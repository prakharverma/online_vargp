{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.optim.fit import fit_gpytorch_torch\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import FixedNoiseGP, SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import HorseshoePrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc49f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../std_bayesopt/\")\n",
    "from utils import initialize_model_unconstrained as initialize_model\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from trbo import TurboState, update_state, generate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc873188",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50\n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rover_function import create_large_domain\n",
    "def l2cost(x, point):\n",
    "    return 10 * np.linalg.norm(x - point, 1)\n",
    "\n",
    "domain = create_large_domain(\n",
    "    force_start=False,\n",
    "    force_goal=False,\n",
    "    start_miss_cost=l2cost,\n",
    "    goal_miss_cost=l2cost,\n",
    "    n_points=dim, \n",
    ")\n",
    "n_points = domain.traj.npoints\n",
    "\n",
    "raw_x_range = np.repeat(domain.s_range, n_points, axis=1)\n",
    "# 5 is the max achievable, this is the offset\n",
    "bounded_fn_callable = lambda X: torch.stack([torch.tensor(domain(x.cpu().numpy()) + 5.) for x in X]).to(X)\n",
    "# map into bounds, thanks..\n",
    "# we need to map this from [0, 1]^d -> [-0.1, 1.1]^d\n",
    "fn_callable = lambda X: bounded_fn_callable(X * 1.2 - 0.1)\n",
    "bounds = torch.tensor(raw_x_range, dtype=dtype, device=device)\n",
    "bounds = torch.zeros(2, raw_x_range.shape[-1], dtype=dtype, device=device)\n",
    "bounds[1] = 1.\n",
    "dim = bounds.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_candidates = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_x = torch.rand(800, bounds.shape[-1], device=device, dtype=dtype) * \\\n",
    "    (bounds[1] - bounds[0]) + bounds[0]\n",
    "next_obj = fn_callable(next_x).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c307df",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # generate a new model\n",
    "            mll_gibbon, model = initialize_model(\n",
    "                next_x, \n",
    "                next_obj, \n",
    "                None,\n",
    "                method=\"exact\",\n",
    "                use_input_transform=False,\n",
    "                use_outcome_transform=True,\n",
    "                num_inducing=500,\n",
    "                loss=\"pll\",\n",
    "            )\n",
    "            # fit the models\n",
    "            optimizer_kwargs = {\"maxiter\": 1000}\n",
    "            fit_gpytorch_torch(mll_gibbon, options=optimizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1563b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # generate a new model\n",
    "            mll_gibbon, svgp = initialize_model(\n",
    "                next_x, \n",
    "                next_obj, \n",
    "                None,\n",
    "                method=\"variational\",\n",
    "                use_input_transform=False,\n",
    "                use_outcome_transform=True,\n",
    "                num_inducing=500,\n",
    "                loss=\"pll\",\n",
    "            )\n",
    "            # fit the models\n",
    "            optimizer_kwargs = {\"maxiter\": 1000}\n",
    "            fit_gpytorch_torch(mll_gibbon, options=optimizer_kwargs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77767094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trbo import generate_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3298f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_path(candidate_sets, model, tree_depth, orig_topk):\n",
    "    post_samples = model.posterior(candidate_sets[0]).rsample().squeeze(0)\n",
    "    samples, inds = torch.topk(post_samples, dim=-2, k=orig_topk)\n",
    "    \n",
    "    if candidate_sets[0].ndim < 3:\n",
    "        cs = candidate_sets[0][inds]\n",
    "    else:\n",
    "        cs = torch.stack([candidate_sets[0][i, inds[i]] for i in range(inds.shape[0])])\n",
    "\n",
    "    fantasy = model.condition_on_observations(\n",
    "        cs,\n",
    "        samples.unsqueeze(-1)\n",
    "    )\n",
    "    pred_root_list = []\n",
    "    pred_root_list.append(fantasy.prediction_strategy.lik_train_train_covar.root_decomposition())\n",
    "    for depth in range(tree_depth - 1):\n",
    "        post_samples = fantasy.posterior(candidate_sets[depth+1]).rsample().squeeze(0)\n",
    "        samples, inds = torch.topk(post_samples, dim=-2, k=1)\n",
    "        fantasy = fantasy.condition_on_observations(\n",
    "            candidate_sets[depth+1][inds].squeeze(-2),\n",
    "            samples,\n",
    "        )\n",
    "        pred_root_list.append(fantasy.prediction_strategy.lik_train_train_covar.root_decomposition())\n",
    "        \n",
    "    targets = fantasy.train_targets\n",
    "    return fantasy.train_inputs[0][..., -tree_depth:, :], targets[..., -tree_depth:], pred_root_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ba5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_topk = 10\n",
    "tree_depth = 16\n",
    "length = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the TR to be proportional to the lengthscales\n",
    "x_center = next_x[next_obj.argmax(), :].clone()\n",
    "weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "weights = weights / weights.mean()\n",
    "weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "tr_lb = torch.clamp(x_center - weights * length / 2.0, 0.0, 1.0)\n",
    "tr_ub = torch.clamp(x_center + weights * length / 2.0, 0.0, 1.0)\n",
    "\n",
    "dim = next_x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_candidates = 1000\n",
    "candidates = [generate_candidates(\n",
    "    x_center, dim, rollout_candidates, torch.stack([tr_lb, tr_ub]), device=device, dtype=dtype\n",
    ")] * tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs, targets, roots = rollout_path(candidates, model, tree_depth, orig_topk)\n",
    "    # inputs, targets = inputs.cpu(), targets.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    exact_train_evals = model.covar_module(inputs.reshape(-1, dim)).symeig()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = [x.evaluate().double().symeig()[0].cpu().detach().numpy().T for x in roots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    var_inputs, var_targets, var_roots = rollout_path(candidates, svgp, tree_depth, orig_topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f840407",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    var_train_evals = svgp.covar_module(inputs.reshape(-1, 60)).symeig()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_evals = [x.evaluate().double().symeig()[0].cpu().detach().numpy().T for x in var_roots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_cond = np.stack(x[-1] / x[0] for x in evals)\n",
    "var_cond = np.stack(x[-1] / x[0] for x in var_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_mean = np.mean(exact_cond, 1)\n",
    "exact_std = np.std(exact_cond, 1)\n",
    "\n",
    "var_mean = np.mean(var_cond, 1)\n",
    "var_std = np.std(var_cond, 1)\n",
    "\n",
    "sem = 2 / (10 ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(16), exact_mean, color = \"orange\", linewidth = 4, marker = \"x\", markersize=10, label = \"Exact\")\n",
    "plt.fill_between(np.arange(16), exact_mean + exact_std * sem, exact_mean - exact_std * sem, color = \"orange\",\n",
    "                alpha = 0.1)\n",
    "plt.plot(np.arange(16), var_mean, color = \"purple\", linewidth = 4, marker = \"x\", markersize=10, label = \"OVC\")\n",
    "plt.fill_between(np.arange(16), var_mean + var_std * sem, var_mean - var_std * sem, color = \"purple\",\n",
    "                alpha = 0.1)\n",
    "\n",
    "# plt.plot([np.mean(x[-1] / x[0]) for x in evals], marker = \"x\", label = \"Exact\")\n",
    "# plt.plot([np.mean(x[-1] / x[0]) for x in var_evals], marker = \"x\", label = \"OVC\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Rollout Depth\")\n",
    "plt.ylabel(\"Condition Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy([x[0] for x in evals], color = \"blue\", label = \"Exact\", marker = \"x\")\n",
    "plt.semilogy([x[0] for x in var_evals], color = \"orange\", label = \"OVC\", marker = \"x\")\n",
    "# plt.legend()\n",
    "plt.grid()\n",
    "plt.ylabel(\"Smallest Eigenvalue\")\n",
    "plt.xlabel(\"Rollout Depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da40d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(exact_train_evals.cpu(), label = \"Exact\")\n",
    "plt.semilogy(var_train_evals.cpu(), label = \"SVGP\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19efb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"evals\": evals, \"var_evals\": var_evals, \n",
    "    \"exact_evals_train\": exact_train_evals.cpu(), \"var_evals_train\": var_train_evals.cpu(),\n",
    "},\n",
    "    \"conditioning_experiment_100.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
