{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"bright\")\n",
    "\n",
    "sns.set(font_scale=2.0)\n",
    "sns.set_style('whitegrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_gp.models.streaming_sgpr import StreamingSGPR, StreamingSGPRBound\n",
    "from gpytorch import mlls, kernels\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_plot(model, x, y, old_x=None, old_y=None, bounds=(-6., 6.)):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_x = torch.linspace(*bounds).view(-1,1)\n",
    "        pred_dist = model.likelihood(model(test_x))\n",
    "        pred_induc = model.variational_strategy.variational_distribution.mean\n",
    "        \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.plot(test_x, pred_dist.mean, label = \"Predictive Mean\", color = \"#3dbbdb\", linewidth=4)\n",
    "    plt.fill_between(test_x.view(-1), *[x.detach() for x in pred_dist.confidence_region()], \n",
    "                     alpha = 0.3, color = \"#3dbbdb\")\n",
    "    \n",
    "    plt.scatter(x, y, color = \"#6d6d6d\", label = \"Current Data\", s=50, zorder=1)\n",
    "    plt.scatter(model.variational_strategy.inducing_points.data, pred_induc.detach(), \n",
    "            color = \"#d71e5e\", marker=\"*\", label = \"Inducing Points\", s=150, zorder=100)\n",
    "    if old_x is not None:\n",
    "        plt.scatter(old_x, old_y, color = \"#6d6d6d\", alpha = 0.3, label = \"Old Data\", s=50, zorder=1)\n",
    "    sns.despine()\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$y$', rotation=0)\n",
    "        \n",
    "#     plt.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bounds = (-1, 1)\n",
    "batch_size = 16\n",
    "num_init = num_z = 16\n",
    "num_steps = 1040\n",
    "shuffle = True\n",
    "\n",
    "assert num_z <= num_init\n",
    "\n",
    "x_train = torch.linspace(*x_bounds, num_steps)\n",
    "y_train = torch.sin(6 * x_train) + math.sqrt(1e-2) * torch.randn(x_train.size(0))\n",
    "if shuffle:\n",
    "    row_perm = torch.randperm(x_train.size(0))\n",
    "    x_train, y_train = x_train[row_perm], y_train[row_perm]\n",
    "    \n",
    "x_init, x_train = x_train[:num_init], x_train[num_init:]\n",
    "y_init, y_train = y_train[:num_init], y_train[num_init:]\n",
    "\n",
    "x_perm = torch.randperm(x_init.size(0))[:num_z]\n",
    "z_init = x_init[x_perm].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module = kernels.RBFKernel()\n",
    "ssgp = StreamingSGPR(z_init, covar_module=covar_module, learn_inducing_locations=True, num_data=x_init.size(0),\n",
    "                    jitter=1e-3)\n",
    "elbo = mlls.VariationalELBO(ssgp.likelihood, ssgp, num_data=x_init.size(0))\n",
    "mll = mlls.ExactMarginalLogLikelihood(ssgp.likelihood, ssgp)\n",
    "trainable_params = [\n",
    "    dict(params=ssgp.likelihood.parameters(), lr=1e-1),\n",
    "    dict(params=ssgp.covar_module.parameters(), lr=1e-1),\n",
    "    dict(params=ssgp.variational_strategy.inducing_points, lr=1e-2),\n",
    "    dict(params=ssgp.variational_strategy._variational_distribution.parameters(), lr=1e-2)\n",
    "]\n",
    "optimizer = torch.optim.Adam(trainable_params)\n",
    "\n",
    "ssgp.train()\n",
    "records = []\n",
    "for i in range(400):\n",
    "    optimizer.zero_grad()\n",
    "    loss = -elbo(ssgp(x_init), y_init)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    evidence = mll(ssgp(x_init), y_init)\n",
    "    records.append(dict(elbo=-loss.item(), evidence=evidence.item(),\n",
    "                        noise=ssgp.likelihood.noise.item()))\n",
    "ssgp.eval()\n",
    "ssgp.disable_q_grad()\n",
    "# ssgp.likelihood.requires_grad_(False)\n",
    "\n",
    "z_init = ssgp.variational_strategy.inducing_points.clone().detach()\n",
    "z_init = z_init.sort(dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(df.evidence, label='Evidence')\n",
    "ax.plot(df.elbo, label='ELBO')\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(df.noise)\n",
    "ax.set_ylabel('noise')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "_ = make_basic_plot(ssgp, x_init, y_init, bounds=x_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_update_steps = batch_size\n",
    "num_chunks = x_train.size(0) // batch_size\n",
    "x_seen = x_last = x_init\n",
    "y_seen = y_last = y_init\n",
    "records = []\n",
    "for t, (new_x, new_y) in enumerate(zip(x_train.chunk(num_chunks), y_train.chunk(num_chunks))):\n",
    "\n",
    "    ssgp.eval()\n",
    "    pred_y = ssgp(new_x.view(-1))\n",
    "    \n",
    "    ssgp = ssgp.get_fantasy_model(x_last.view(-1, 1), y_last.view(-1, 1), resample_ratio=0.)\n",
    "    elbo = StreamingSGPRBound(ssgp, combine_terms=False)\n",
    "    mll = mlls.ExactMarginalLogLikelihood(ssgp.likelihood, ssgp)\n",
    "    trainable_params = [\n",
    "        dict(params=ssgp.likelihood.parameters(), lr=1e-3),\n",
    "        dict(params=ssgp.covar_module.parameters(), lr=1e-3),\n",
    "        dict(params=ssgp.variational_strategy.inducing_points, lr=1e-4)\n",
    "    ]\n",
    "    optimizer = torch.optim.Adam(trainable_params)\n",
    "    \n",
    "    ssgp.train()\n",
    "    for _ in range(num_update_steps):\n",
    "        optimizer.zero_grad()\n",
    "        logp_term, trace_term, t1, t2 = elbo(new_x.view(-1, 1), new_y.view(-1, 1))\n",
    "        loss = -(logp_term + trace_term)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        evidence = mll(ssgp(x_seen), y_seen)\n",
    "        z_now = ssgp.variational_strategy.inducing_points.clone().detach()\n",
    "        z_now = z_now.sort(dim=0).values\n",
    "        z_disp = (z_init - z_now).norm() / z_init.norm()\n",
    "        records.append(dict(elbo=-loss.item(), evidence=evidence.item(),\n",
    "                            noise=ssgp.likelihood.noise.item(), logp_term=logp_term.item(),\n",
    "                            trace_term=trace_term.item(), z_disp=z_disp.item(),\n",
    "                            t1=t1.item(), t2=t2.item()))\n",
    "        \n",
    "    x_seen = torch.cat([x_seen, new_x])\n",
    "    y_seen = torch.cat([y_seen, new_y])\n",
    "    x_last, y_last = new_x, new_y\n",
    "\n",
    "    if t % (num_chunks // 4) == (num_chunks // 4 - 1):\n",
    "        fig = make_basic_plot(ssgp, x_seen, y_seen, bounds=x_bounds)\n",
    "#         plt.title(f'T = {(t + 1) * batch_size}')\n",
    "        plt.show(fig)\n",
    "        fig.savefig(f'sgpr_{batch_size}_sine_{(t+1) * batch_size}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.plot(df.evidence, label='Evidence')\n",
    "ax.plot(df.logp_term, label='logp(\\hat y)')\n",
    "# ax.plot(df.elbo, label='ELBO')\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "\n",
    "# ax.plot(df.t1, label='t1')\n",
    "ax.plot(df.t1 + df.t2, label='trace', color='darkblue')\n",
    "ax.fill_between(range(len(df)), np.zeros_like(df.t1.values), df.t1, label='t1', color='blue', alpha=0.3)\n",
    "ax.fill_between(range(len(df)), df.t1, df.t1 + df.t2, label='t2', color='lightblue', alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.plot(df.noise)\n",
    "ax.set_ylabel('noise')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.plot(df.z_disp)\n",
    "ax.set_ylabel('z displacement')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(df.t1 + df.t2, label='trace', color='#330662')\n",
    "ax.fill_between(range(len(df)), np.zeros_like(df.t1.values), df.t1, label=r'$\\mathrm{trace}_1$', \n",
    "                color='#57068c', alpha=0.3)\n",
    "ax.fill_between(range(len(df)), df.t1, df.t1 + df.t2, label=r'$\\mathrm{trace}_2$', \n",
    "                color='#8900e1', alpha=0.3)\n",
    "# plt.title(f'batch_size={batch_size}')\n",
    "plt.ylim((0, 0.3))\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend(loc='upper right')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'sgpr_{batch_size}_sine_trace.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
