{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"bright\")\n",
    "\n",
    "sns.set(font_scale=2.0)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from volatilitygp.likelihoods import VolatilityGaussianLikelihood\n",
    "from volatilitygp.models import SingleTaskVariationalGP as SingleTaskCopulaProcessModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "torch.random.manual_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = 10 ## init price\n",
    "V0 = 0.2 ## init price\n",
    "mu = 0.05 ## rate of return\n",
    "\n",
    "alpha = 1.25\n",
    "beta = 0.9\n",
    "rho = -0.2\n",
    "\n",
    "T = 1 ## Time of Simulation\n",
    "steps = 400 ## steps per time\n",
    "dt = 1./(steps * T) ## delta t\n",
    "\n",
    "dW = np.random.normal(0, np.sqrt(dt), steps*T)\n",
    "dZ = rho * dW + np.sqrt(1 - rho **2) * np.random.normal(0, np.sqrt(dt), steps*T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.zeros(steps*T)\n",
    "V = np.zeros(steps*T)\n",
    "\n",
    "F[0] = F0\n",
    "V[0] = V0\n",
    "\n",
    "for t in range(1, steps*T):\n",
    "    F[t] = F[t-1] + V[t-1] * (F[t-1])**beta * dW[t]\n",
    "    V[t] = V[t-1] + alpha * V[t-1]*dZ[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(F, label='Price')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(V, color='OrangeRed', label='Vol')\n",
    "\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax2.set_ylabel(\"Vol\")\n",
    "\n",
    "fig.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_returns =np.log(F[1:]/F[:-1])\n",
    "scaled_returns = (F[1:] - F[:-1]) / (F[:-1]**beta) / dt**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(scaled_returns, label='Log Returns')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(V, color='OrangeRed', label='Vol')\n",
    "\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax2.set_ylabel(\"Vol\")\n",
    "\n",
    "fig.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now apply GCPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_x = torch.FloatTensor(np.arange(steps*T-1))\n",
    "full_y = torch.FloatTensor(scaled_returns)\n",
    "\n",
    "train_x = full_x[:250]\n",
    "train_y = full_y[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = VolatilityGaussianLikelihood()\n",
    "model = SingleTaskCopulaProcessModel(\n",
    "    init_points=torch.linspace(0, T*steps, 100).view(-1,1), likelihood=likelihood, use_piv_chol_init=False,\n",
    "    mean_module = gpytorch.means.ZeroMean(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iterations = 2 if smoke_test else 250\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.parameters()}, \n",
    "    # {\"params\": likelihood.parameters(), \"lr\": 0.1}\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# num_data refers to the number of training datapoints\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_y.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50\n",
    "for i in range(training_iterations):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    with gpytorch.settings.num_gauss_hermite_locs(75):\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        if i % print_every == 0:\n",
    "            print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "likelihood.eval();\n",
    "predictive = model(train_x)\n",
    "pred_scale = likelihood(predictive, return_gaussian=False).scale.mean(0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictive.mean.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "plt.plot(train_x, pred_scale, label = \"Predicted\")\n",
    "plt.plot(full_x, V[1:], label = \"Actual\", color = \"orangered\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigma(x)\")\n",
    "plt.legend()\n",
    "\n",
    "# fig, ax = plt.subplots(dpi=100)\n",
    "# ax.plot(train_x, pred_scale, label = \"Predicted\")\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.plot(train_x, V[1:], label = \"Actual\", color='orangered')\n",
    "\n",
    "# ax.set_ylabel(\"Predicted Vol\")\n",
    "# ax2.set_ylabel(\"Actual Vol\")\n",
    "\n",
    "\n",
    "# fig.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictive.mean.detach())\n",
    "plt.title(\"Posterior Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_model = model.get_fantasy_model(full_x[250:].view(-1,1), full_y[250:], targets_are_gaussian=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpytorch.settings.cholesky_jitter(1e-3):\n",
    "    fant_dist = fantasy_model.posterior(full_x).mvn\n",
    "    predictive_dist = likelihood(fant_dist, return_gaussian = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictive_scale = predictive_dist.scale\n",
    "predictive_scale_mean = predictive_scale.mean(0).detach()\n",
    "predictive_scale_std = predictive_scale.std(0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fantasy_model(full_x).mean.detach())# - model(full_x).mean.detach() + fantasy_model.mean_module.constant.detach())\n",
    "plt.plot(model(full_x).mean.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_scale = likelihood(model(full_x) , return_gaussian=False).scale\n",
    "\n",
    "orig_scale_mean = orig_scale.mean(0).detach()\n",
    "orig_scale_std = orig_scale.std(0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.light_palette(\"#57068c\", 10, reverse=True)\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6.5))\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# ax.scatter(train_x, train_y, color = palette[4], label = \"Training Points\", marker = \"x\", s = 100, alpha = 0.3)\n",
    "# ax.scatter(test_points, test_values, color = palette[2], label = \"Fantasy Points\", s = 100, alpha = 0.3)\n",
    "\n",
    "ax2.plot(full_x, orig_scale_mean.detach(), label = \"Original Model\", color = palette[-2], linewidth=3)\n",
    "ax2.fill_between(full_x, orig_scale_mean - 2 * orig_scale_std,\n",
    "                orig_scale_mean + 2 * orig_scale_std, alpha = 0.1, color = palette[-2])\n",
    "\n",
    "ax2.plot(full_x, predictive_scale_mean.detach(), label = \"Fantasy Prediction\", color = palette[0], linewidth=3)\n",
    "ax2.fill_between(full_x, predictive_scale_mean - 2*predictive_scale_std,\n",
    "                predictive_scale_mean + 2* predictive_scale_std, alpha = 0.1, color = palette[0])\n",
    "\n",
    "ax.scatter(full_x[:250], train_y, label = \"Training Points\", color = palette[4], marker = \"x\", s = 100, alpha = 0.3)\n",
    "ax.scatter(full_x[250:], full_y[250:], label = \"Fantasy Points\", color = palette[2], s = 100, alpha = 0.3)\n",
    "\n",
    "# plt.plot(full_x[:250], V[1:][:250], label = \"True Volatility\", color = palette[4], linewidth=3)\n",
    "# plt.plot(full_x[250:], V[1:][250:], label = \"Fantasy Points\", color = palette[2], linewidth=3)\n",
    "plt.plot(full_x, V[1:], linestyle=\"--\", color = palette[4], linewidth=3, zorder=0)\n",
    "ax2.set_ylim((0, 0.6))\n",
    "ax.set_ylim((-0.6, 0.6))\n",
    "ax.set_ylabel(\"y\")\n",
    "# plt.legend()\n",
    "# plt.ylim((0, 1))\n",
    "plt.xlim((-5, 405))\n",
    "ax.grid()\n",
    "# plt.grid()\n",
    "ax.set_xlabel(\"x\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "# plt.savefig(\"fantasization_gpcv.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (8, 7), sharex=True, sharey=True, dpi=300)\n",
    "\n",
    "ax2 = ax[0].twinx()\n",
    "ax3 = ax[1].twinx()\n",
    "\n",
    "ax2.scatter(full_x[:250], train_y, label = \"Training Points\", \n",
    "            color = \"#d71e5e\", marker = \"x\", s = 100, zorder=0, alpha = 0.5)\n",
    "ax3.scatter(full_x[:250], train_y, label = \"Training Points\", \n",
    "            color = \"#d71e5e\", marker = \"x\", s = 100, zorder=0, alpha = 0.1)\n",
    "ax3.scatter(full_x[250:], full_y[250:], label = \"Fantasy Points\", \n",
    "            color = \"#d71e5e\", s = 100, marker = \"x\", zorder=0, alpha = 0.5)\n",
    "\n",
    "ax[0].plot(full_x, orig_scale_mean.detach(), label = \"Original Model\", color = palette[3], linewidth=3,\n",
    "          zorder=100)\n",
    "ax[0].fill_between(full_x, orig_scale_mean - 2 * orig_scale_std,\n",
    "                orig_scale_mean + 2 * orig_scale_std, alpha = 0.2, color = palette[3],\n",
    "                  zorder=100)\n",
    "\n",
    "ax[1].plot(full_x, predictive_scale_mean.detach(), label = \"Fantasy Prediction\", color = palette[0], linewidth=3,\n",
    "          zorder=100)\n",
    "ax[1].fill_between(full_x, predictive_scale_mean - 2*predictive_scale_std,\n",
    "                predictive_scale_mean + 2* predictive_scale_std, alpha = 0.2, color = palette[0],\n",
    "                  zorder=100)\n",
    "\n",
    "\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "\n",
    "ax[0].plot(full_x, V[1:], linestyle=\"--\", color = \"#6d6d6d\", linewidth=3, zorder=50)\n",
    "ax[1].plot(full_x, V[1:], linestyle=\"--\", color = \"#6d6d6d\", linewidth=3, zorder=50)\n",
    "\n",
    "# ax2.set_ylim((0, 0.6))\n",
    "ax[0].set_ylabel(\"Volatility\")\n",
    "ax[1].set_ylabel(\"Volatility\")\n",
    "ax[0].set_ylim((0., 0.35))\n",
    "\n",
    "ax2.set_ylabel(\"y\")\n",
    "ax3.set_ylabel(\"y\")\n",
    "# ax2.set_ylim((-1.5, 0.5))\n",
    "# ax3.set_ylim((-1.5, 0.5))\n",
    "ax[0].set_xlabel(\"x\")\n",
    "ax[1].set_xlabel(\"x\")\n",
    "# plt.savefig(\"fantasization_svgp_gpcv.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
